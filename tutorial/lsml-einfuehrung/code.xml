<lecture>
    
    <info 
        title="Eine Einfuehrung in LSML"
        description="Dies ist eine kurze Einfuehrung in die Markup Sprache LSML."
    />
    <settings 
        voice="amazon-de-de-vicki"
        resolution="1920x1080"
        fps="30"     
        breakAfterSlide="1300"
        breakAfterParagraph="550"
    />

    <deck id="slides" src="lsml-tutorial.pdf" active="true" />

    Willkommen zu einer Demonstration der Funktionen der Markup Sprache <say-as interpret-as="characters">LSML</say-as>.
    
    <slide page="2" />
    
    Hier seht ihr den Programmcode der gerade vorgelesen wird. Aber bevor wir uns mit Code auseinandersetzen, kommen wir erst einmal zum Wesentlichen.
    
    <slide page="3" />
    
    <say-as interpret-as="characters">LSML</say-as> steht für <en>Lecture Synthesis Markup Language</en>, und ist eine Sprache um Vorlesungen visuell und audial, sowie menschen- und maschinenlesbar, in Textform zu definieren. 
    
    <slide page="4" />
    
    <say-as interpret-as="characters">LSML</say-as> basiert auf der hierarchisch strukturierten Auszeichnungs-Sprache <say-as interpret-as="characters">XML</say-as>. <say-as interpret-as="characters">XML</say-as> als Grundlage zu verwenden bietet einige Vorteile, da es weit verbreitet ist, mit vielen existierenden Bibliotheken.
    
    Der größte Vorteil jedoch ist, dass bereits eine auf <say-as interpret-as="characters">XML</say-as> basierende Sprache existiert, welche Sprachsynthese ermöglicht.
    
    <say-as interpret-as="characters">SSML</say-as>, beziehungsweise <en>Speech Synthesis Markup Language</en>, wurde von dem <en>World Wide Web Consortium</en> entwickelt um die Aussprache von Texten zu definieren. Mittlerweile wird <say-as interpret-as="characters">SSML</say-as> von vielen <en>Text-to-Speech</en> Diensten verwendet. Dazu gehören auch <en>Amazon Polly</en> und <en>Google Cloud Text-to-Speech</en>, welche in <en>Lecture</en> <say-as interpret-as="characters">js</say-as> integriert werden sollen.
    
    <slide page="5" />
    
    <say-as interpret-as="characters">SSML</say-as> definiert bereits viele Elemente, die von <say-as interpret-as="characters">LSML</say-as> übernommen werden können. Aber da die <en>Text-to-Speech</en> Dienste diesen Standard nur unvollständig und teils unterschiedlich implementieren, müssen einige Elemente durch <say-as interpret-as="characters">LSML</say-as> angepasst werden.
    
    <slide page="6" />
    
    Manche Elemente sind auch zu eingeschränkt für die Verwendung in <say-as interpret-as="characters">LSML</say-as>, weshalb diese entfernt werden.
    
    <slide page="7" />
    
    Diese Elemente werden durch neue Elemente ersetzt.
    
    <slide page="8" />
    
    Zusätzlich kommen noch weitere Elemente dazu, die die visuellen Aspekte der Vorlesung steuern. Dazu gehört zum Beispiel, welche Folie wann gezeigt wird, oder welche Einstellungen das Video haben soll. 
    
    Die Herausforderung dabei ist es, <say-as interpret-as="characters">LSML</say-as> so einfach wie möglich zu halten und <en>Clutter</en> zu vermeiden, um es auch Nicht-Programmierern zu ermöglichen die Sprache zu verwenden.
    
    Die Tabelle sieht kompliziert aus, aber keine Sorge! Wir schauen uns jetzt kurz die wichtigsten Funktionen der Sprache an, und damit wird es hoffentlich gleich viel übersichtlicher!
    
    <slide page="9" />
    
    Jedes Dokument beginnt mit einem <en>lecture</en> Element. Dies ist das Wurzelelement und beinhaltet alle anderen Elemente, sowie den Text der gesprochen werden soll.
    
    <slide page="10" />
    
    Es wird auch ein <en>deck</en> Element definiert. Dieses referenziert ein <say-as interpret-as="characters">PDF</say-as> Dokument, was den Foliensatz für die Vorlesung enthält. Es können mehrere Foliensätze eingebunden werden, aber es muss immer mindestens einer vorhanden sein.
    
    <slide page="11" />
    
    Jetzt könnte man theoretisch schon seinen Text schreiben und diesen als Video rendern lassen. Das Beispiel hier würde wie folgt aussehen.
    
    <slide page="12" />
    
    <voice name="amazon-de-de-hans">
        Das wird gesprochen.
    </voice>
    
    <slide page="13" />
    
    Wie euch auffällt, wurde automatisch erkannt, dass es sich um einen Satz handelt, und dieser wurde ausgesprochen.
    
    <slide page="14" />
    
    Falls dies aber fehlschlägt, kann man explizit den Paragraphen mit dem <emphasis level="strong">p</emphasis> Element und den Satz mit dem <emphasis level="strong">s</emphasis> Element definieren. Das ist aber meist nicht nötig und das Endprodukt ist oft dasselbe.
    
    <slide page="15" />
    
    <voice name="amazon-de-de-hans">
        Das wird gesprochen.
    </voice>
    
    
    
    
    
    <slide page="16" />
    
    Man kann die Seite wechseln mittels des <en>slide</en> Elements.
    
    <slide page="+1" />
    
    Dieses definiert die relative oder absolute Seitenzahl, und der darauffolgende Text wird über der entsprechenden Folie gesprochen.
    
    <slide page="+1" />
    
    Nun kann man mit diesem Element auch einfach den aktiven Foliensatz ändern. In diesem Beispiel werden 2 Foliensätze geladen. Der erste Foliensatz ist von Anfang an aktiv, und der zweite Foliensatz wird ab Zeile 8 angewendet.
    
    <slide page="+1" />
    
    <voice name="amazon-de-de-hans">
        Das wird gesprochen.
    </voice>
    
    <slide page="+1" />
    
    <voice name="amazon-de-de-hans">
        Das wird auf Seite 2 gesprochen.
    </voice>
    
    <slide page="+1" />
    
    <voice name="amazon-de-de-hans">
        Das wird auf Seite 1 des zweiten Foliensatzes gesprochen.
    </voice>

    
    
    
    
    <slide page="22" />
    
    Um dem Vortrag Struktur zu geben, kann man auch <en>marker</en> integrieren, mit denen man optional Kapitel definieren kann.
    
    <slide page="+1" />
    
    <voice name="amazon-de-de-hans">
        Das ist die Einleitung.
        <break time="1s" />
        Das ist Kapitel 2.
    </voice>
    
    
    
    
    <slide page="24" />
    
    Natürlich kann man auch verschiedene Stimmen verwenden mit dem <en>voice</en> Element. Das ermöglicht es zum Beispiel einen Dialog nachzuspielen.
    
    <slide page="+1" />
    
    <voice name="google-es-es-wavenet-b">
        Hola como estas?
    </voice>
    
    <voice name="amazon-en-us-kimberly">
        I'm fine! Thank you for asking!
    </voice>
    
    
    
    
    
    
    
    <slide page="26" />
    
    Um das Gesprochene interessanter zu gestalten, kann man auch manuell Pausen einfügen und bestimmte Segmente betonen wie in diesem Beispiel. Hören wir uns es doch einfach mal an.
    
    <slide page="+1" />
    
    <voice name="amazon-de-de-hans">
        Hier wird eine <break time="1000ms" /> Pause eingefügt.
        
        Und dieser Satz wird <emphasis level="strong">stark betont.</emphasis>
        
        <break time="1500ms" />
    </voice>
    
    
    
    
    <slide page="28" />
    
    Es gibt mehrere Möglichkeiten um die falsche Aussprache von Wörtern zu korrigieren. Zum Beispiel existiert das <en>sub</en> Element, welches es ermöglicht einen <en>alias</en> zu definieren.
    
    In dem Code-Beispiel wird hier das Akronym <say-as interpret-as="characters">AB</say-as> definiert. Jedoch wird stattdessen der <en>alias</en> "Alpha Beta" gesprochen.
    
    <slide page="+1" />
    
    <voice name="amazon-de-de-hans">
        
        <sub alias="Alpha Beta">AB</sub>
        
        <break time="1500ms" />
    </voice>
    
    
    
    
    <slide page="30" />
    
    Man kann dem Geschriebenen natürlich auch zusätzlichen Kontext geben mit dem <en>say as</en> Element. Dieses definiert wie sein Inhalt interpretiert werden soll. 
    
    In diesem Beispiel wird das Programm angewiesen die Zahlen als Nummern aufzuzählen, anstatt "Einhundertdreiundzwanzig" zu sagen.
    
    <slide page="+1" />
    
    <voice name="amazon-de-de-hans">
        
        <say-as interpret-as="characters">123</say-as>
        
        <break time="1500ms" />
    </voice>
    
    
    
    
    
    
    <slide page="32" />
    
    <say-as interpret-as="characters">LSML</say-as> ermöglicht auch das Einfügen von anderen Ressourcen, nicht nur <en>slides</en>. Zum Beispiel ist es möglich eigene Videos zu drehen und diese dann mit <say-as interpret-as="characters">LSML</say-as> einzufügen.
    
    In dem folgenden Beispiel wird ein Video für 3 Sekunden abgespielt.
    
    <video src="video-example.mp4" clipEnd="3s" />
    
    
    
    <slide page="33" />
    
    Neben Folien kann man natürlich auch Bilder direkt in das Video einbinden. Mit diesem Codeschnipsel hier wird ein Beispielbild eingefügt.
    
    <voice name="amazon-de-de-hans">
        <image src="image-example.png" />
        Das ist ein Beispielbild.
    </voice>
    
    
    
    <slide page="34" />
    
    Das war die Demonstration. Natürlich gibt es noch mehr, aber das ist hoffentlich dennoch eine gute Übersicht.
    
    Zum Abschluss kommt noch eine kleine Melodie.
    
    <audio src="audio-example.m4a" />
    
</lecture>